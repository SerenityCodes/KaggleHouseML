{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>1456</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>175000</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>1457</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>210000</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>1458</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>GdPrv</td>\n      <td>Shed</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>266500</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>1459</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>142125</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>1460</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>147500</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 81 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nfor column in X_train_full.columns:\\n    check = np.array(X_train_full[X_train_full[column] > 1])\\n    if True in check:\\n        X_train_full[column] = scaler.fit_transform(np.array(X_train_full[column]).reshape(train.shape[0], 1))\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_full = train.drop(\"SalePrice\", axis=1)\n",
    "y_train_full = train[\"SalePrice\"]\n",
    "'''\n",
    "for column in X_train_full.columns:\n",
    "    check = np.array(X_train_full[X_train_full[column] > 1])\n",
    "    if True in check:\n",
    "        X_train_full[column] = scaler.fit_transform(np.array(X_train_full[column]).reshape(train.shape[0], 1))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_vaild, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DecisionTreeRegressor 44619.98015109786\n",
      "LinearRegression 35070.7660056117\n",
      "LinearSVR 70671.60964181625\n",
      "RandomForestRegressor 31863.471281150043\n",
      "KNeighborsRegressor 49471.30544837903\n",
      "GradientBoostingRegressor 29608.53161883225\n"
     ]
    }
   ],
   "source": [
    "models = [DecisionTreeRegressor(max_depth=5), LinearRegression(), LinearSVR(), RandomForestRegressor(n_estimators=100), KNeighborsRegressor(), GradientBoostingRegressor()]\n",
    "\n",
    "for model in models:\n",
    "    score = cross_val_score(model, X_train_prepared, y_train_full, cv=5, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "    print(model.__class__.__name__, np.mean(np.sqrt(-score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'RL'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-af26a56179a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    302\u001b[0m             )\n\u001b[0;32m    303\u001b[0m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[1;32m--> 304\u001b[1;33m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0m\u001b[0;32m    305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1781\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1783\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'RL'"
     ]
    }
   ],
   "source": [
    "forest = RandomForestRegressor(n_estimators=100)\n",
    "forest.fit(X_trai, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.sqrt(-cross_val_score(forest, X_train, y_train, cv=3, n_jobs=-1, scoring=\"neg_mean_squared_error\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": range(50, 200, 10),\n",
    "    \"max_features\": range(1, 20),\n",
    "    \"max_depth\": range(1, 10),\n",
    "    \"min_samples_leaf\": range(),\n",
    "    \"min_samples_split\": [2],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-2767a3aea876>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_prepared\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-35a9e867629b>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# Label Encoding of the SubClass (Higher number means a higher price)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(pipeline., y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 90}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores: \", scores)\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"Standard Deviation: \", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores:  [40143.09715728 23564.37746856 32671.03257647 24463.9170943\n 29227.15823667]\nMean:  30013.916506655933\nStandard Deviation:  6044.478510473171\n"
     ]
    }
   ],
   "source": [
    "random_search_scores = cross_val_score(grid_search.best_estimator_, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "random_search_scores = np.sqrt(-random_search_scores)\n",
    "display_scores(random_search_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['best_estimator.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(grid_search.best_estimator_, \"best_estimator.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores:  [nan nan nan nan nan]\nMean:  nan\nStandard Deviation:  nan\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "forest = joblib.load(\"best_estimator.pkl\")\n",
    "random_search_scores = cross_val_score(forest, X_train_full, y_train_full, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "random_search_scores = np.sqrt(-random_search_scores)\n",
    "display_scores(random_search_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        assert type(X) is pd.DataFrame\n",
    "\n",
    "        # Label Encoding of the SubClass (Higher number means a higher price)\n",
    "        values = [20, 30, 40, 45, 50, 60, 70, 75, 80, 85, 90, 120, 150, 160, 180, 190]\n",
    "        for value in values:\n",
    "            X.loc[X[\"MSSubClass\"] == value, \"MSSubClass\"] = values.index(value)\n",
    "        \n",
    "        # Whether or not the house is in a residential area (1 is Y, 0 is N)\n",
    "        X[\"Residential\"] = np.where((X[\"MSZoning\"] == \"RL\") | (X[\"MSZoning\"] == \"RM\"), 1, 0)\n",
    "        X = X.drop(\"MSZoning\", axis=1)\n",
    "\n",
    "        # Whether the street the house is on is paved or not\n",
    "        X[\"Paved\"] = np.where(X[\"Street\"] == \"Pave\", 1, 0)\n",
    "        X = X.drop(\"Street\", axis=1)\n",
    "\n",
    "        # If the house has a regular or irregular lot shape\n",
    "        X[\"RegularLotShape\"] = np.where(X[\"LotShape\"] == \"Reg\", 1, 0)\n",
    "        X = X.drop(\"LotShape\", axis=1)\n",
    "\n",
    "        # If the house has a level contour or not\n",
    "        X[\"LevelContour\"] = np.where(X[\"LandContour\"] == \"Lvl\", 1, 0)\n",
    "        X = X.drop(\"LandContour\", axis=1)\n",
    "\n",
    "        # Turning the five options into having utilities or not\n",
    "        X[\"Utilities\"] = X[\"Utilities\"].fillna(0)\n",
    "        X[\"AllUtilities\"] = np.where(X[\"Utilities\"] == \"AllPub\", 1, 0)\n",
    "        X = X.drop(\"Utilities\", axis=1)\n",
    "\n",
    "        # Whether or not the house is on the inside or corner of a street\n",
    "        X[\"InsideStreet\"] = np.where(X[\"LotConfig\"] == \"Inside\", 1, 0)\n",
    "        X = X.drop(\"LotConfig\", axis=1)\n",
    "\n",
    "        # Single family or other\n",
    "        X[\"SingleFam\"] = np.where(X[\"BldgType\"] == \"1Fam\", 1, 0)\n",
    "        X = X.drop(\"BldgType\", axis=1)\n",
    "\n",
    "        # Age of Home since 2010 or last remodel\n",
    "        X[\"Age\"] = list(abs(X[\"YearBuilt\"] - X[\"YearRemodAdd\"]))\n",
    "        X = X.drop([\"YearBuilt\", \"YearRemodAdd\"], axis=1)\n",
    "\n",
    "        X[\"CentralAir\"] = np.where(X[\"CentralAir\"] == \"Y\", 1, 0)\n",
    "\n",
    "        # Defines the scoring dict to be used through the next features\n",
    "        scoring_dict = {\n",
    "            \"Ex\": 5,\n",
    "            \"Gd\": 4,\n",
    "            \"TA\": 3,\n",
    "            \"Fa\": 2,\n",
    "            \"Po\": 1,\n",
    "            \"Av\": 3,\n",
    "            \"Mn\": 2,\n",
    "            \"No\": 1,\n",
    "            \"GLQ\": 6,\n",
    "            \"ALQ\": 5,\n",
    "            \"BLQ\": 4,\n",
    "            \"Rec\": 3,\n",
    "            \"LwQ\": 2,\n",
    "            \"Unf\": 1,\n",
    "            \"SBrkr\": 4,\n",
    "            \"FuseA\": 3,\n",
    "            \"FuseF\": 2,\n",
    "            \"FuseP\": 1,\n",
    "            \"Mix\": 2,\n",
    "            \"Y\": 3,\n",
    "            \"P\": 2,\n",
    "            \"N\": 1,\n",
    "            \"Fin\": 3,\n",
    "            \"RFn\": 2,\n",
    "            \"Unf\": 1\n",
    "        }\n",
    "\n",
    "        exter_columns = [\"ExterQual\", \"ExterCond\"]\n",
    "        for column in exter_columns:\n",
    "            for key in scoring_dict:\n",
    "                X.loc[X[column] == key, column] = scoring_dict[key]\n",
    "        bsmt_columns = [\"BsmtQual\", \"BsmtCond\"]\n",
    "        X[\"FinalBsmtQual\"] = np.zeros((X.shape[0], 1))\n",
    "        for column in bsmt_columns:\n",
    "            X[column] = X[column].fillna(0)\n",
    "            for key in scoring_dict:\n",
    "                X.loc[X[column] == key, column] = scoring_dict[key]\n",
    "            X[\"FinalBsmtQual\"] += X[column]\n",
    "            X = X.drop(column, axis=1)\n",
    "        \n",
    "        for key in scoring_dict:\n",
    "            X.loc[X[\"BsmtExposure\"] == key, \"BsmtExposure\"] = scoring_dict[key]\n",
    "\n",
    "        X[\"FinalBsmtQual\"] += X[\"BsmtExposure\"]\n",
    "        X = X.drop(\"BsmtExposure\", axis=1)\n",
    "\n",
    "        for i in range(1, 3):\n",
    "            X[f\"BsmtFinType{i}\"] = X[f\"BsmtFinType{i}\"]\n",
    "            X[f\"BsmtFinType{i}\"] = X[f\"BsmtFinType{i}\"].fillna(0)\n",
    "            for key in scoring_dict:\n",
    "                X.loc[X[f\"BsmtFinType{i}\"] == key, f\"BsmtFinType{i}\"] = scoring_dict[key]\n",
    "\n",
    "            X[\"FinalBsmtQual\"] += X[f\"BsmtFinType{i}\"].astype(np.int8)\n",
    "            X = X.drop(f\"BsmtFinType{i}\", axis=1)\n",
    "\n",
    "        X[\"BsmtSF\"] = X[\"TotalBsmtSF\"]\n",
    "        X = X.drop(\"TotalBsmtSF\", axis=1)\n",
    "\n",
    "        X[\"HeatingQual\"] = X[\"HeatingQC\"]\n",
    "        X[\"ElectricQC\"] = X[\"Electrical\"]\n",
    "\n",
    "        for key in scoring_dict:\n",
    "            X.loc[X[\"HeatingQual\"] == key, \"HeatingQual\"] = scoring_dict[key]\n",
    "            X.loc[X[\"ElectricQC\"] == key, \"ElectricQC\"] = scoring_dict[key]\n",
    "\n",
    "        X[\"TotalSF\"] = X[\"1stFlrSF\"] + X[\"2ndFlrSF\"]\n",
    "        X = X.drop([\"1stFlrSF\", \"2ndFlrSF\"], axis=1)\n",
    "\n",
    "        X[\"Bathrooms\"] = X[\"FullBath\"] + (X[\"HalfBath\"] / 2)\n",
    "        X = X.drop([\"FullBath\", \"HalfBath\"], axis=1)\n",
    "\n",
    "        X[\"Bedrooms\"] = X[\"BedroomAbvGr\"]\n",
    "        X = X.drop([\"BedroomAbvGr\"], axis=1)\n",
    "\n",
    "        for key in scoring_dict:\n",
    "            X.loc[X[\"KitchenQual\"] == key, \"KitchenQual\"] = scoring_dict[key]\n",
    "\n",
    "        X[\"Functional\"] = np.where(X[\"Functional\"] == \"Typ\", 1, 0)\n",
    "\n",
    "        X[\"FireplaceQual\"] = X[\"FireplaceQu\"]\n",
    "        X[\"FireplaceQual\"] = X[\"FireplaceQual\"].fillna(0)\n",
    "\n",
    "        for key in scoring_dict:\n",
    "            X.loc[X[\"FireplaceQual\"] == key, \"FireplaceQual\"] = scoring_dict[key]\n",
    "        \n",
    "        garage_names = [\"GarageQual\", \"GarageCond\", \"GarageFinish\", \"PavedDrive\"]\n",
    "        X[\"GarageScore\"] = np.zeros((X.shape[0], 1))\n",
    "\n",
    "        for column in garage_names:\n",
    "            X[column] = X[column]\n",
    "            X[column] = X[column].fillna(0)\n",
    "            for key in scoring_dict:\n",
    "                X.loc[X[column] == key, column] = scoring_dict[key]\n",
    "            X[\"GarageScore\"] += X[column]\n",
    "            X = X.drop(column, axis=1)\n",
    "\n",
    "        porch_columns = [\"OpenPorchSF\", \"WoodDeckSF\", \"EnclosedPorch\", \"3SsnPorch\", \"ScreenPorch\"]\n",
    "        X[\"PorchArea\"] = np.zeros((X.shape[0], 1))\n",
    "\n",
    "        for column in porch_columns:\n",
    "            X[\"PorchArea\"] += X[column]\n",
    "\n",
    "        X[\"Pool\"] = np.where((X[\"PoolQC\"] == \"Ex\") | (X[\"PoolQC\"] == \"Fa\") | (X[\"PoolQC\"] == \"Gd\") | (X[\"PoolQC\"] == \"TA\"), 1, 0)\n",
    "\n",
    "        X[\"LuxuryItems\"] = np.where((X[\"MiscFeature\"] == \"Elev\") | (X[\"MiscFeature\"] == \"TenC\"), 1, 0)\n",
    "        X[\"LuxuryValue\"] = X[\"MiscVal\"]\n",
    "\n",
    "        for column in X.columns:\n",
    "            if column not in pd.read_csv(\"train_preproccesed.csv\"):\n",
    "                X = X.drop(column, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = FeatureEngineering()\n",
    "X_train_bad = engine.transform(X_train_full)\n",
    "X_train_good = pd.read_csv(\"train_preproccesed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ExterQual [4 3 5 2]\nExterCond [3 4 2 1 5]\nKitchenQual [4 3 5 2]\nFinalBsmtQual [15.0 17.0 16.0 14.0 18.0 9.0 11.0 13.0 12.0 nan 10.0 19.0 8.0 20.0 7.0\n 6.0 21.0 23.0]\nHeatingQual [5 4 3 2 1]\nElectricQC [4 2 3 1 nan]\nFireplaceQual [0 3 4 2 5 1]\nGarageScore [11.0 10.0 9.0 12.0 8.0 7.0 1.0 3.0 6.0 16.0 4.0 13.0 5.0 2.0 14.0]\n"
     ]
    }
   ],
   "source": [
    "from pandas.api.types import is_string_dtype\n",
    "for column in X_train_bad.columns:\n",
    "    if is_string_dtype(X_train_bad[column]):\n",
    "        print(column, X_train_bad[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MSSubClass           0\n",
       "LotFrontage        259\n",
       "LotArea              0\n",
       "OverallQual          0\n",
       "OverallCond          0\n",
       "ExterQual            0\n",
       "ExterCond            0\n",
       "CentralAir           0\n",
       "KitchenQual          0\n",
       "Functional           0\n",
       "Residential          0\n",
       "Paved                0\n",
       "RegularLotShape      0\n",
       "LevelContour         0\n",
       "AllUtilities         0\n",
       "InsideStreet         0\n",
       "SingleFam            0\n",
       "Age                  0\n",
       "FinalBsmtQual       38\n",
       "BsmtSF               0\n",
       "HeatingQual          0\n",
       "ElectricQC           1\n",
       "TotalSF              0\n",
       "Bathrooms            0\n",
       "Bedrooms             0\n",
       "FireplaceQual        0\n",
       "GarageScore          0\n",
       "PorchArea            0\n",
       "Pool                 0\n",
       "LuxuryItems          0\n",
       "LuxuryValue          0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "X_train_bad.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"transformer\", FeatureEngineering()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=10, min_samples_leaf=2, n_estimators=90)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "X_train_prepared = pipeline.fit_transform(X_train_full)\n",
    "forest = RandomForestRegressor(n_estimators=90, bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2)\n",
    "forest.fit(X_train_prepared, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores:  [25045.91479324 27052.95730764 24068.54269603 48416.92734289\n 36418.78985666 26507.82978346 28094.6171509  22852.84042029\n 41977.77348417 28419.27108212]\nMean:  30885.54639173912\nStandard Deviation:  8085.949212702041\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(forest, X_train_prepared, y_train_full, cv=10, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "display_scores(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prepared = pipeline.fit_transform(test)\n",
    "predictions = forest.predict(X_test_prepared)\n",
    "id = np.arange(1461, 2920)\n",
    "submission = pd.DataFrame({\"Id\": id, \"SalePrice\": predictions})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": range(50, 200, 10),\n",
    "    \"max_features\": range(1, 20),\n",
    "    \"max_depth\": range(5, 10),\n",
    "    \"min_samples_leaf\": [2],\n",
    "    \"min_samples_split\": [2],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingRegressor(), param_grid, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GradientBoostingRegressor 29324.93369388859\n",
      "RandomForestRegressor 31565.284844506405\n",
      "ElasticNet 36162.64462679459\n"
     ]
    }
   ],
   "source": [
    "for model in [GradientBoostingRegressor(), RandomForestRegressor(), ElasticNet()]:\n",
    "    score = cross_val_score(model, X_train_prepared, y_train_full, cv=5, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "    print(model.__class__.__name__, np.mean(np.sqrt(-score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': range(5, 10),\n",
       "                         'max_features': range(1, 20), 'min_samples_leaf': [2],\n",
       "                         'min_samples_split': [2],\n",
       "                         'n_estimators': range(50, 200, 10)},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "grid_search.fit(X_train_prepared, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores:  [24336.83542402 26311.06307802 23716.64365701 38481.61219807\n 33924.28891414 26082.32560522 27628.30036508 22205.97465024\n 35424.00502062 25731.30300325]\nMean:  28384.23519156779\nStandard Deviation:  5251.215600684015\n"
     ]
    }
   ],
   "source": [
    "forest = grid_search.best_estimator_\n",
    "scores = cross_val_score(forest, X_train_prepared, y_train_full, cv=10, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "display_scores(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}